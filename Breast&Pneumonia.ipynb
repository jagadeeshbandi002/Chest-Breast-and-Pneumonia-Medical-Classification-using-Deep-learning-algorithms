{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from medmnist import BreastMNIST, PneumoniaMNIST\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import timm\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings\n",
    "\n",
    "# Set random seed and device\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and loading functions\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.shape[0] == 1 else x),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def load_dataset(dataset_name, sample_size=100):  # Reduced to 100 samples\n",
    "    if dataset_name == 'breast':\n",
    "        dataset = BreastMNIST\n",
    "    elif dataset_name == 'pneumonia':\n",
    "        dataset = PneumoniaMNIST\n",
    "    \n",
    "    data_transform = get_transform()\n",
    "    \n",
    "    # Load datasets\n",
    "    train_dataset = dataset(split='train', transform=data_transform, download=True)\n",
    "    val_dataset = dataset(split='val', transform=data_transform, download=True)\n",
    "    test_dataset = dataset(split='test', transform=data_transform, download=True)\n",
    "    \n",
    "    # Reduce dataset sizes\n",
    "    train_indices = random.sample(range(len(train_dataset)), min(sample_size, len(train_dataset)))\n",
    "    val_indices = random.sample(range(len(val_dataset)), min(sample_size//2, len(val_dataset)))\n",
    "    test_indices = random.sample(range(len(test_dataset)), min(sample_size//2, len(test_dataset)))\n",
    "    \n",
    "    train_dataset = Subset(train_dataset, train_indices)\n",
    "    val_dataset = Subset(val_dataset, val_indices)\n",
    "    test_dataset = Subset(test_dataset, test_indices)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=16, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions\n",
    "class ResNet18Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18Model, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.resnet.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "class ViTModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViTModel, self).__init__()\n",
    "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "        self.vit.head = nn.Linear(self.vit.head.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vit(x)\n",
    "\n",
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DenseNetModel, self).__init__()\n",
    "        self.densenet = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "        self.densenet.classifier = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and evaluation functions\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):\n",
    "    best_val_auc = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device).long().squeeze()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.squeeze()\n",
    "                outputs = model(inputs)\n",
    "                val_preds.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "                val_targets.extend(targets.numpy())\n",
    "        \n",
    "        val_preds = np.array(val_preds)\n",
    "        val_targets = np.array(val_targets)\n",
    "        \n",
    "        # Calculate AUC\n",
    "        try:\n",
    "            val_auc = roc_auc_score(val_targets, val_preds[:, 1])\n",
    "        except ValueError:\n",
    "            val_auc = roc_auc_score(np.eye(outputs.shape[1])[val_targets], val_preds, multi_class='ovr')\n",
    "        \n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_model = model.state_dict().copy()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss/len(train_loader):.4f}, Val AUC: {val_auc:.4f}')\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    test_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.squeeze()\n",
    "            outputs = model(inputs)\n",
    "            test_preds.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "            test_targets.extend(targets.numpy())\n",
    "    \n",
    "    test_preds = np.array(test_preds)\n",
    "    test_targets = np.array(test_targets)\n",
    "    \n",
    "    try:\n",
    "        test_auc = roc_auc_score(test_targets, test_preds[:, 1])\n",
    "    except ValueError:\n",
    "        test_auc = roc_auc_score(np.eye(outputs.shape[1])[test_targets], test_preds, multi_class='ovr')\n",
    "    \n",
    "    return test_auc\n",
    "\n",
    "# Training loop for all models and datasets\n",
    "datasets = ['breast', 'pneumonia']\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet18 for all datasets...\n",
      "\n",
      "Processing breast dataset\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/breastmnist.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.7663, Val AUC: 0.6012\n",
      "Epoch 2/5, Loss: 0.6418, Val AUC: 0.5496\n",
      "Epoch 3/5, Loss: 0.3928, Val AUC: 0.6944\n",
      "Epoch 4/5, Loss: 0.3454, Val AUC: 0.7599\n",
      "Epoch 5/5, Loss: 0.4242, Val AUC: 0.6230\n",
      "Test AUC for breast: 0.4883\n",
      "\n",
      "Processing pneumonia dataset\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/pneumoniamnist.npz\n",
      "Epoch 1/5, Loss: 0.8718, Val AUC: 0.8710\n",
      "Epoch 2/5, Loss: 0.3263, Val AUC: 0.9127\n",
      "Epoch 3/5, Loss: 0.1014, Val AUC: 0.9782\n",
      "Epoch 4/5, Loss: 0.0594, Val AUC: 0.9841\n",
      "Epoch 5/5, Loss: 0.2470, Val AUC: 0.9067\n",
      "Test AUC for pneumonia: 0.9618\n"
     ]
    }
   ],
   "source": [
    "# ResNet18 for all datasets\n",
    "print(\"\\nTraining ResNet18 for all datasets...\")\n",
    "for dataset_name in datasets:\n",
    "    print(f\"\\nProcessing {dataset_name} dataset\")\n",
    "    train_loader, val_loader, test_loader = load_dataset(dataset_name)\n",
    "    num_classes = 2\n",
    "    \n",
    "    model = ResNet18Model(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    best_model = train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "    model.load_state_dict(best_model)\n",
    "    test_auc = test_model(model, test_loader)\n",
    "    \n",
    "    results[f'ResNet18_{dataset_name}'] = test_auc\n",
    "    torch.save(best_model, f'ResNet18_{dataset_name}_best.pth')\n",
    "    print(f\"Test AUC for {dataset_name}: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ViT for all datasets...\n",
      "\n",
      "Processing breast dataset\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/breastmnist.npz\n",
      "Epoch 1/5, Loss: 6.0969, Val AUC: 0.6317\n",
      "Epoch 2/5, Loss: 1.3313, Val AUC: 0.4336\n",
      "Epoch 3/5, Loss: 0.8201, Val AUC: 0.4476\n",
      "Epoch 4/5, Loss: 0.6495, Val AUC: 0.4522\n",
      "Epoch 5/5, Loss: 0.9351, Val AUC: 0.4615\n",
      "Test AUC for breast: 0.5439\n",
      "\n",
      "Processing pneumonia dataset\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/pneumoniamnist.npz\n",
      "Epoch 1/5, Loss: 3.8433, Val AUC: 0.6992\n",
      "Epoch 2/5, Loss: 1.1974, Val AUC: 0.6938\n",
      "Epoch 3/5, Loss: 0.7142, Val AUC: 0.6883\n",
      "Epoch 4/5, Loss: 0.8019, Val AUC: 0.6911\n",
      "Epoch 5/5, Loss: 0.7924, Val AUC: 0.6992\n",
      "Test AUC for pneumonia: 0.5401\n"
     ]
    }
   ],
   "source": [
    "# ViT for all datasets\n",
    "print(\"\\nTraining ViT for all datasets...\")\n",
    "for dataset_name in datasets:\n",
    "    print(f\"\\nProcessing {dataset_name} dataset\")\n",
    "    train_loader, val_loader, test_loader = load_dataset(dataset_name)\n",
    "    num_classes = 2\n",
    "    \n",
    "    model = ViTModel(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    best_model = train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "    model.load_state_dict(best_model)\n",
    "    test_auc = test_model(model, test_loader)\n",
    "    \n",
    "    results[f'ViT_{dataset_name}'] = test_auc\n",
    "    torch.save(best_model, f'ViT_{dataset_name}_best.pth')\n",
    "    print(f\"Test AUC for {dataset_name}: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training DenseNet for all datasets...\n",
      "\n",
      "Processing breast dataset\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/breastmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/breastmnist.npz\n",
      "Epoch 1/5, Loss: 0.5896, Val AUC: 0.7676\n",
      "Epoch 2/5, Loss: 0.3794, Val AUC: 0.8305\n",
      "Epoch 3/5, Loss: 0.2297, Val AUC: 0.7905\n",
      "Epoch 4/5, Loss: 0.2855, Val AUC: 0.8952\n",
      "Epoch 5/5, Loss: 0.1778, Val AUC: 0.9219\n",
      "Test AUC for breast: 0.8686\n",
      "\n",
      "Processing pneumonia dataset\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/pneumoniamnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/pneumoniamnist.npz\n",
      "Epoch 1/5, Loss: 0.3718, Val AUC: 0.8503\n",
      "Epoch 2/5, Loss: 0.1638, Val AUC: 0.9605\n",
      "Epoch 3/5, Loss: 0.1426, Val AUC: 0.9272\n",
      "Epoch 4/5, Loss: 0.2275, Val AUC: 0.9231\n",
      "Epoch 5/5, Loss: 0.0536, Val AUC: 0.9418\n",
      "Test AUC for pneumonia: 0.9409\n"
     ]
    }
   ],
   "source": [
    "# DenseNet for all datasets\n",
    "print(\"\\nTraining DenseNet for all datasets...\")\n",
    "for dataset_name in datasets:\n",
    "    print(f\"\\nProcessing {dataset_name} dataset\")\n",
    "    train_loader, val_loader, test_loader = load_dataset(dataset_name)\n",
    "    num_classes = 2\n",
    "    \n",
    "    model = DenseNetModel(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    best_model = train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "    model.load_state_dict(best_model)\n",
    "    test_auc = test_model(model, test_loader)\n",
    "    \n",
    "    results[f'DenseNet_{dataset_name}'] = test_auc\n",
    "    torch.save(best_model, f'DenseNet_{dataset_name}_best.pth')\n",
    "    print(f\"Test AUC for {dataset_name}: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "ResNet18_breast: 0.4883\n",
      "ResNet18_pneumonia: 0.9618\n",
      "ViT_breast: 0.5439\n",
      "ViT_pneumonia: 0.5401\n",
      "DenseNet_breast: 0.8686\n",
      "DenseNet_pneumonia: 0.9409\n",
      "\n",
      "Best model for breast: DenseNet_breast with AUC: 0.8686\n",
      "\n",
      "Best model for pneumonia: ResNet18_pneumonia with AUC: 0.9618\n"
     ]
    }
   ],
   "source": [
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "for model_dataset, auc in results.items():\n",
    "    print(f\"{model_dataset}: {auc:.4f}\")\n",
    "\n",
    "# Find best model for each dataset\n",
    "for dataset_name in datasets:\n",
    "    dataset_results = {k: v for k, v in results.items() if dataset_name in k}\n",
    "    best_model = max(dataset_results.items(), key=lambda x: x[1])\n",
    "    print(f\"\\nBest model for {dataset_name}: {best_model[0]} with AUC: {best_model[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
