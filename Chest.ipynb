{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from medmnist import ChestMNIST\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import timm\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Suppress warnings\n",
    "\n",
    "# Set random seed and device\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing and loading functions\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.repeat(3, 1, 1) if x.shape[0] == 1 else x),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def load_dataset(dataset_name, sample_size=1000):  # Increased sample size to 1000\n",
    "    if dataset_name == 'chest':\n",
    "        dataset = ChestMNIST\n",
    "    \n",
    "    data_transform = get_transform()\n",
    "    \n",
    "    # Load datasets\n",
    "    train_dataset = dataset(split='train', transform=data_transform, download=True)\n",
    "    val_dataset = dataset(split='val', transform=data_transform, download=True)\n",
    "    test_dataset = dataset(split='test', transform=data_transform, download=True)\n",
    "    \n",
    "    # Reduce dataset sizes\n",
    "    train_indices = random.sample(range(len(train_dataset)), min(sample_size, len(train_dataset)))\n",
    "    val_indices = random.sample(range(len(val_dataset)), min(sample_size//2, len(val_dataset)))\n",
    "    test_indices = random.sample(range(len(test_dataset)), min(sample_size//2, len(test_dataset)))\n",
    "    \n",
    "    train_dataset = Subset(train_dataset, train_indices)\n",
    "    val_dataset = Subset(val_dataset, val_indices)\n",
    "    test_dataset = Subset(test_dataset, test_indices)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)  # Increased batch size\n",
    "    val_loader = DataLoader(dataset=val_dataset, batch_size=32, shuffle=False)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definitions remain the same\n",
    "class ResNet18Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18Model, self).__init__()\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.resnet.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "class ViTModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ViTModel, self).__init__()\n",
    "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "        self.vit.head = nn.Linear(self.vit.head.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.vit(x)\n",
    "\n",
    "class DenseNetModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DenseNetModel, self).__init__()\n",
    "        self.densenet = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "        self.densenet.classifier = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.densenet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc(targets, preds, multi_label=True):\n",
    "    try:\n",
    "        if multi_label:\n",
    "            # Handle cases where a class might be missing\n",
    "            mask = targets.sum(axis=0) > 0\n",
    "            if mask.sum() == 0:\n",
    "                return 0.0\n",
    "            return roc_auc_score(targets[:, mask], preds[:, mask], average='macro')\n",
    "        else:\n",
    "            return roc_auc_score(targets, preds, multi_class='ovr')\n",
    "    except ValueError:\n",
    "        return 0.0  # Return 0 if AUC cannot be calculated\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=5):\n",
    "    best_val_auc = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device).float()  # Convert to float for BCE loss\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "                val_targets.extend(targets.numpy())\n",
    "        \n",
    "        val_preds = np.array(val_preds)\n",
    "        val_targets = np.array(val_targets)\n",
    "        \n",
    "        val_auc = calculate_auc(val_targets, val_preds)\n",
    "        \n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_model = model.state_dict().copy()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss/len(train_loader):.4f}, Val AUC: {val_auc:.4f}')\n",
    "    \n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet18 for chest dataset...\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/chestmnist.npz\n",
      "Epoch 1/5, Loss: 0.2427, Val AUC: 0.5983\n",
      "Epoch 2/5, Loss: 0.1802, Val AUC: 0.6470\n",
      "Epoch 3/5, Loss: 0.1770, Val AUC: 0.6167\n",
      "Epoch 4/5, Loss: 0.1769, Val AUC: 0.6109\n",
      "Epoch 5/5, Loss: 0.1709, Val AUC: 0.6425\n",
      "Test AUC for chest: 0.5681\n",
      "\n",
      "Training ViT for chest dataset...\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/chestmnist.npz\n",
      "Epoch 1/5, Loss: 0.2589, Val AUC: 0.5115\n",
      "Epoch 2/5, Loss: 0.1931, Val AUC: 0.5148\n",
      "Epoch 3/5, Loss: 0.1892, Val AUC: 0.5295\n",
      "Epoch 4/5, Loss: 0.1945, Val AUC: 0.5374\n",
      "Epoch 5/5, Loss: 0.1888, Val AUC: 0.5190\n",
      "Test AUC for chest: 0.5509\n",
      "\n",
      "Training DenseNet for chest dataset...\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/chestmnist.npz\n",
      "Using downloaded and verified file: /home/codespace/.medmnist/chestmnist.npz\n",
      "Epoch 1/5, Loss: 0.2191, Val AUC: 0.5930\n",
      "Epoch 2/5, Loss: 0.1767, Val AUC: 0.6201\n",
      "Epoch 3/5, Loss: 0.1669, Val AUC: 0.5942\n",
      "Epoch 4/5, Loss: 0.1703, Val AUC: 0.6294\n",
      "Epoch 5/5, Loss: 0.1684, Val AUC: 0.6468\n",
      "Test AUC for chest: 0.6360\n"
     ]
    }
   ],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_preds = []\n",
    "    test_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            test_preds.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "            test_targets.extend(targets.numpy())\n",
    "    \n",
    "    test_preds = np.array(test_preds)\n",
    "    test_targets = np.array(test_targets)\n",
    "    \n",
    "    return calculate_auc(test_targets, test_preds)\n",
    "\n",
    "# Training loop\n",
    "datasets = ['chest']\n",
    "results = {}\n",
    "\n",
    "# Training for each model type\n",
    "models_to_train = [\n",
    "    ('ResNet18', ResNet18Model),\n",
    "    ('ViT', ViTModel),\n",
    "    ('DenseNet', DenseNetModel)\n",
    "]\n",
    "\n",
    "for model_name, model_class in models_to_train:\n",
    "    print(f\"\\nTraining {model_name} for chest dataset...\")\n",
    "    train_loader, val_loader, test_loader = load_dataset('chest')\n",
    "    num_classes = 14\n",
    "    \n",
    "    model = model_class(num_classes).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    best_model = train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "    model.load_state_dict(best_model)\n",
    "    test_auc = test_model(model, test_loader)\n",
    "    \n",
    "    results[f'{model_name}_chest'] = test_auc\n",
    "    torch.save(best_model, f'{model_name}_chest_best.pth')\n",
    "    print(f\"Test AUC for chest: {test_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Results:\n",
      "ResNet18_chest: 0.5681\n",
      "ViT_chest: 0.5509\n",
      "DenseNet_chest: 0.6360\n",
      "\n",
      "Best model overall: DenseNet_chest with AUC: 0.6360\n"
     ]
    }
   ],
   "source": [
    "# Print final results\n",
    "print(\"\\nFinal Results:\")\n",
    "for model_dataset, auc in results.items():\n",
    "    print(f\"{model_dataset}: {auc:.4f}\")\n",
    "\n",
    "# Find best model\n",
    "best_model = max(results.items(), key=lambda x: x[1])\n",
    "print(f\"\\nBest model overall: {best_model[0]} with AUC: {best_model[1]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
